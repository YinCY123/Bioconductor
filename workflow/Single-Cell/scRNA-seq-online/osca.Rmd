---
title: "Orchestrating Single-Cell Analysis with Bioconductor"
author: "yincy"
date: "2/28/2020"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE, message = FALSE, warning = FALSE)
```

# Chapter 1 Introduction  
```{r}
library(SingleCellExperiment)
```

### Workflows  
All workflows begin with data import and subsequent *quality control and normalization*, going from a raw (count) expression matrix to a clean one. This includes adjusting for experimental factors and possibly even latent factors. Using the clean expression matrix, *feature selection* strategies can be applied to select the features (genes) driving heterogeneity. Furthermore, these features can then be used to perform *dimensionality reduction*, which enables downstream analysis that would not otherwise be possible and visualization in 2 or 3 dimensions.  

From there, the workflows largely focus on differing downstream analyses. *Clustering* details how to segment a scRNA-seq dataset, and *differential expression* provides a means to determine what drives the differences between different groups of cells. *Integrating datasets* walks through merging scRNA-seq datasets, an area of need as the number of scRNA-seq datasets continues to grow and comparisons between datasets must be done. Finally, we touch upon how to work with *large scale data*, specifically where it becomes impractical or impossible to work with data solely in-memory.  


# Chapter 2 Learning R and Bioconductor  
- Codecademy [Learn R Series](https://www.codecademy.com/learn/learn-r)
- [R for Data Science](https://r4ds.had.co.nz/)book.  
- [tidyverse](https://www.tidyverse.org/) ecosystem  
- [Bioconductor Courses](https://bioconductor.org/help/course-materials/)  


# Chapter 3 Beyond R Basics  
## Becoming an R Expert  
- [Advanced R](https://adv-r.hadley.nz/)  
- [programming with S4](https://adv-r.hadley.nz/s4.html)  
- [R packages](http://r-pkgs.had.co.nz/)  
- [What They Forgot to Teach You About R](https://whattheyforgot.org/)  
- [R Inferno](https://www.burns-stat.com/pages/Tutor/R_inferno.pdf)  


## Nice Companions for R  
While not essential for our purposes, many bioinformatic tools for processing raw sequencing data require knowledge beyond just R to install, run, and import their results into R for further analysis. The most important of which are basic knowledge of the Shell/Bash utilities, for working with bioinformatic pipelines and troubleshooting (R package) installation issues.  

Additionally, for working with packages or software that are still in development and not hosted on an official repository like CRAN or Bioconductor, knowledge of Git - a version control system - and the popular GitHub hosting service is helpful. This enables you to not only work with other people’s code, but also better manage your own code to keep track of changes.  


### Shell/Bash  
[Shell/Bash](https://www.datacamp.com/courses/tech:shell)  

### Git
[Git](https://www.datacamp.com/courses/tech:git)  

### Other Languages  
- Python  
- C++ (Rcpp)  

# Chapter 4 Data Infrastructure  
## Background  
One of the main strengths of the Bioconductor project lies in the use of a common data infrastructure that powers interoperability across packages. Users should be able to analyze their data using functions from different Bioconductor packages without the need to convert between formats.  

```{r, fig.align='center', fig.cap='Overview of the structure of the 'SingleCellExperiment' class. Each row of the assyas corresponds to a row of the 'rowData'(pink shading), while each column of the assyas corresponds to a column of the 'colData' and 'reducedDims'(yellow shading).'}
knitr::include_graphics("figures/SingleCellExperiment.png")
```

Each piece of (meta)data in the `SingeCellExperiment` is represented by a separate 'slot'. (This terminology comes from the [S4 class system](https://adv-r.hadley.nz/s4.html)).  

## Storing primary experimental data  
### Filling the `assays` slot  
To construct a rudimentary `SingleCellExperiment` object, we only need to fill the `assays` slot. This contains primary data such as a matrix of sequencing counts where rows correspond to features (genes) and columns correspond to samples (cells).  

```{r}
counts_matrix <- data.frame(
    cell_1 = rpois(10, 10), 
    cell_2 = rpois(10, 10), 
    cell_3 = rpois(10, 30)
)

rownames(counts_matrix) <- paste("gene_", 1:10, sep = "")

counts_matrix <- as.matrix(counts_matrix) # must be a matrix object
```

```{r}
sce <- SingleCellExperiment(assays = list(counts = counts_matrix))
```

```{r}
sce
```

To access the count data  

- `assay(sce, "counts")`  
- `counts(sce)`  

```{r}
counts(sce)
```

```{r}
assays(sce, "counts")[[1]]
```

### Adding more `assays`  
What makes the `assays` slot especially powerful is that it can hold multiple representations of the primary data. This is especially useful for storing the raw count matrix as well as a normalized version of the data. We can do just that as shown below, using the `scater` package to compute a normalized and log-transformed representation of the initial primary data.  

```{r}
sce <- scater::logNormCounts(x = sce)
sce
```

```{r}
logcounts(sce)
```

```{r}
assays(sce)
```

```{r}
counts_100 <- counts(sce) + 100
assay(sce, "counts_100") <- counts_100 # assign a new entry to assays slot
assays(sce)
```


## Handling metadata  
### On the columns  
To further annotate our `SingleCellExperiment` object, we can add metadata to describe the columns of our primary data, e.g., the samples or cells of our experiment. This data is entered into the `colData` slot, a `data.frame` or `DataFrame` object where rows correspond to cells and columns correspond to metadata fields, e.g., batch of origin, treatment condition.  

```{r}
cell_metadata <- data.frame(batch = c(1, 1, 2))
rownames(cell_metadata) <- paste("cell_", 1:3, sep = "")
```

```{r}
sce <- SingleCellExperiment(assays = list(counts = counts_matrix), 
                            colData = cell_metadata)
sce
```

Access the column data with `colData()`  

```{r}
colData(sce)
```

Access the column data with `$`  

```{r}
sce$batch
```

Some functions automatically add column metadata by returning a `SingleCellExperiment` with extra fields in the `colData` slot. For example, the `scater` package contains the `addPerCellQC()` function that appends a lot of quality control data.  

```{r}
sce <- scater::addPerCellQC(x = sce)
colData(sce)
```

manually add more fields to the column metadata  

```{r}
sce$more_stuff <- runif(ncol(sce))
colnames(colData(sce))
```

A common operation with colData is to use its values for subsetting.  

```{r}
sce[, sce$batch == 1]
```

### On the rows  
To store feature-level annotation, the `SingleCellExperiment` has the `rowData` slot containing a `DataFrame` where each row corresponds to a gene and contains annotations like the transcript length or gene symbol. Furthermore, there is a special `rowRanges` slot to hold genomic coordinates in the form of a `GRanges` or `GRangesList`. This stores describes the chromosome, start, and end coordinates of the features (genes, genomic regions) in a manner that is easy to query and manipulate via the `GenomicRanges` framework.  

Both of the slots can be accessed via their respective accessors, `rowRanges()` and `rowData()`.  

```{r}
rowRanges(sce) # empty
```

```{r}
sce <- scater::addPerFeatureQC(sce)
rowData(sce)
```

The feature data could be provided at the onset when creating the `SingleCellExperiment` object.  

```{r}
library(EnsDb.Hsapiens.v86)
edb <- genes(EnsDb.Hsapiens.v86)

edb[, 2]
```

To subset a `SingleCellExperiment` object at the feature/gene level, we can do a row subsetting operation similar to other R objects, by supplying either **numeric indices or a vector of names**.  

```{r}
sce[c("gene_1", "gene_4"), ]
```

```{r}
sce[c(1, 4), ]
```


### Other metadata  
Some analyses contain results or annotations that do not fit into the aforementioned slots, e.g., study metadata. Thankfully, there is a slot just for this type of messy data - the `metadata` slot, a named list of entries where each entry in the list can be anything you want it to be.  

```{r}
my_genes <- c("gene_1", "gene_5")
metadata(sce) <- list(favorite_genes = my_genes)
metadata(sce)
```

append more information via `$`  
```{r}
your_genes <- c("gene_4", "gene_8")
metadata(sce)$your_genes <- your_genes

metadata(sce)
```


## Single-cell Specific fields  
### Background  
So far, we have covered the `assays` (primary data), `colData` (cell metadata), `rowData`/`rowRanges` (feature metadata), and `metadata` slots (other) of the `SingleCellExperiment` class. These slots are actually inherited from the `SummarizedExperiment` parent class (see here for details), so any method that works on a `SummarizedExperiment` will also work on a `SingleCellExperiment` object.  

### Dimensionality reduction results  
The `reducedDims` slot is specifically designed to store reduced dimensionality representations of the primary data obtained by methods such as PCA and t-SNE. This slot contains a list of numeric matrices of low-reduced representations of the primary data, where the rows represent the columns of the primary data, and columns represent the dimentions. As this slot holds a list, we can store multiple PCA/t-SNE/etc. results for the same dataset.  

```{r}
sce <- scater::logNormCounts(sce)
sce <- scater::runPCA(sce)
reducedDim(sce, "PCA")
```

```{r}
sce <- scater::runTSNE(sce, perplexity = 0.1)
reducedDim(sce, "TSNE")
```

```{r}
reducedDims(sce)
```

manually add content to the `reducedDims()` slot.  

```{r}
u <- uwot::umap(t(logcounts(sce)), n_neighbors = 2)

reducedDim(sce, "UMAP_uwot") <- u
reducedDims(sce)
```

```{r}
reducedDim(sce, "UMAP_uwot")
```

### Alternative Experiments  
The `SingleCellExperiment` class provides the concept of “alternative Experiments” where we have data for a distinct set of features but the same set of samples/cells. The classic application would be to store the per-cell counts for spike-in transcripts; this allows us to retain this data for downstream use but separate it from the `assays` holding the counts for endogenous genes. The separation is particularly important as such alternative features often need to be processed separately.  

If we have data for alternative feature sets, we can store it in our SingleCellExperiment as an alternative Experiment.  

```{r}
spike_counts <- cbind(cell_1 = rpois(5, 10), 
                      cell_2 = rpois(5, 10), 
                      cell_3 = rpois(5, 30))

rownames(spike_counts) <- paste("spike_", 1:5)
spike_se <- SummarizedExperiment(assays = list(counts = spike_counts))
spike_se
```

Then store this `SummarizedExperiment` in our `sce` object via the `altExp()` setter.  

```{r}
altExp(sce, "spike") <- spike_se
altExp(sce)
```

The alternative Experiment concept ensures that all relevant aspects of a single-cell dataset can be held in a single object. It is also convenient as it ensures that our spike-in data is synchronized with the data for the endogenous genes. For example, if we subsetted `sce`, the spike-in data would be subsetted to match.  

```{r}
sub <- sce[, 1:2]
altExp(sub, "spike")
```

Any `SummarizedExperiment` object can be stored as an alternative Experiment, including another `SingleCellExperiment`! This allows power users to perform tricks.   

### Size factors  
The `sizeFactors()` function allows us to get or set a numeric vector of per-cell scaling factors used for normalization. This is typically automatically added by normalization functions.  

```{r}
sce <- scran::computeSumFactors(sce)
sizeFactors(sce)
```

manually add the size factors  

```{r}
sizeFactors(sce) <- scater::librarySizeFactors(sce)
sizeFactors(sce)
```

Technically speaking, the `sizeFactors` concept is not unique to single-cell analyses. Nonetheless, we mention it here as it is an extension beyond what is available in the `SummarizedExperiment` parent class.  


### Column labels  
The `colLabels()` function allows us to get or set a vector or factor of per-cell labels, typically corresponding to groupings assigned by unsupervised clustering (see Chapter 10) or predicted cell type identities from classification algorithms.  

```{r no-this-function, eval=FALSE}
colLabels <- LETTERS[1:3]
colLabels(sce)
```


## Conclusion  
The widespread use of the `SingleCellExperiment` class provides the foundation for interoperability between single-cell-related packages in the Bioconductor ecosystem. `SingleCellExperiment` objects generated by one package can be used as input into another package, encouraging synergies that enable our analysis to be greater than the sum of its parts. Each step of the analysis will also add new entries to the `assays`, `colData`, `reducedDims`, etc., meaning that the final `SingleCellExperiment` object effectively serves as a self-contained record of the analysis. This is convenient as the object can be saved for future use or transferred to collaborators for further analysis.  


# Chapter 5 Overview  
## Introduction  
This chapter provides an overview of the framework of a typical scRNA-seq analysis workflow. Subsequent chapters will describe each analysis in more detail.  

```{r, fig.cap='Schenatic of a typical scRNA-seq analysis workflow. Each stage (separated by dashed lines) consists of a number of specific steps, many of which operate on and modify a `SingleCellExperiment` instance.'}
knitr::include_graphics("figures/scRNA-seq-analysis-workflow.png")
```


## Experimental Design  
Before starting the analysis itself, some comments on experimental design may be helpful. The most obvious question is the choice of technology, which can be roughly divided into:  
- Droplet-based: 10X Genomics, inDrop, Drop-seq  
- Plate-based with unique molecular identifiers (UMIs): CEL-seq, MARS-seq  
- Plate-based with reads: Smart-seq2  
- Other: sci-RNA-seq, Seq-Well  

Papers describe the advantages and weaknesses
- PMID: 32518403  
- PMID: 28212749  

In practical terms, <a style='color="red"'>droplet-based technologies are the current de facto standard due to their throughput and low cost per cell. Plate-based methods can capture other phenotypic information (e.g., morphology) and are more amenable to customization. Read-based methods provide whole-transcript coverage, which is useful in some applications (e.g., splicing, exome mutations); otherwise, UMI-based methods are more popular as they mitigate the effects of PCR amplification noise</a>.  

The next question is how many cells should be captured, and to what depth they should be sequenced. The short answer is “as much as you can afford to spend”. The long answer is that it depends on the aim of the analysis. If we are aiming to discover rare cell subpopulations, then we need more cells. If we are aiming to characterize subtle differences, then we need more sequencing depth. As of time of writing, an informal survey of the literature suggests that typical droplet-based experiments would capture anywhere from 10,000 to 100,000 cells, sequenced at anywhere from 1,000 to 10,000 UMIs per cell (usually in inverse proportion to the number of cells). Droplet-based methods also have a trade-off between throughput and doublet rate that affects the true efficiency of sequencing.  

For studies involving multiple samples or conditions, the design considerations are the same as those for bulk RNA-seq experiments. There should be multiple biological replicates for each condition and conditions should not be confounded with batch. Note that individual cells are not replicates; rather, we are referring to samples derived from replicate donors or cultures.  

## Obtaining a count matrix  
Sequencing data from scRNA-seq experiments must be converted into a matrix of expression values that can be used for statistical analysis. Given the discrete nature of sequencing data, this is usually a count matrix containing the number of UMIs or reads mapped to each gene in each cell. The exact procedure for quantifying expression tends to be technology-dependent:  

- For 10X Genomics data, the `CellRanger` software suite provides a custom pipeline to obtain a count matrix. This uses STAR to align reads to the reference genome and then counts the number of unique UMIs mapped to each gene.  

- Pseudo-alignment methods such as `alevin` can be used to obtain a count matrix from the same data with greater efficiency. This avoids the need for explicit alignment, which reduces the compute time and memory usage.  

- For other highly mutiplexed protocols, the `scPipe` package provides a more general pipeline for processing scRNA-seq data. This uses the `Rsubread` aligner to align reads and then counts UMIs per gene.  

- For CEL-seq or CEL-seq2 data, the `scruff` package provides a dedicated pipline for quantification.  

- For read-based protocols, we can generally re-use the same pipelines for processing bulk RNA-seq data.  

- For any data involving spike-in transcripts, the spike-in sequences should be included as part of the reference genome during alignment and quantification.  

After quantification, we import the count matrix into R and create a `SingleCellExperiment` object. This can be done with base methods (e.g., `read.table()`) followed by applying the `SingleCellExperiment()` constructor. Alternatively, for specific file formats, we can use dedicated methods from the `DropletUtils` (for 10X data) or `tximport`/`tximeta` packages (for pseudo-alignment methods). Depending on the origin of the data, this requires some vigilance:  

- Some feature-counting tools will report mapping statistics in the count matrix (e.g., the number of unaligned or unassigned reads). While these values can be useful for quality control, they would be misleading if treated as gene expression values. Thus should be removed (or at least moved to the `colData`) prior to feature analyses.  

- Be careful of using the `^RECC` regular expression to detect spike-in rows in human data where the row names of the count matrix are gene symbols. An ERCC gene family actually exists in human annotation, so this would result in incorrect identification of genes as spike-in transcripts. This problem can be avoided by using count matrices with standard identifiers (e.g., Ensembl, Entrez).  

## Data Processing and downstream analysis  
In the simplest case, the workflow has the following form:  

1. **We compute quality control metrics to remove low-quality cells that would interfere with downstream analyses**. These cells may have been damaged during processing or may not have been fully captured by the sequencing protocol. Common metrics includes the total counts per cell, the proportion of spike-in or mitochondrial reads and the number of detected features.  

2. **We convert the counts into normalized expression values to elimiinate cell-specific biases** (e.g., in capture efficiency). This allows us to perform explicit comparisons across cells in downstream steps like clustering. **We also apply a transformation, typically log, to adjust for the mean-variance relationship**.  

3. **We perform feature selection to pick a subset of interesting features for downstream analysis**. This is done by modelling the variance across cells for each gene and retaining genes that are highly variable. The aim is to reduce computational overhead and noise from uninteresting genes.   

4. **We apply dimensionality reduction to compact the data and further reduce noise**. Principal components analysis is typically used to obtain an initial low-rank representation for more computational work, followed by more aggressive methods like t-stochastic neighbor embedding for visualization purposes.  

5. **We cluster cells into groups according to similarities in their (normalized) expression profiles**. This aims to obtain groupings that serve as empirical proxies for distinct biological states. We typically interpret these groupings by identifying differentially expressed marker genes between clusters.  


## Quick start  
Here, we use the a droplet-based retina dataset from Macosko et al.([2015](http://dx.doi.org/10.1016/j.cell.2015.05.002)), provided in the scRNAseq package. This starts from a count matrix and finishes with clusters in preparation for biological interpretation. Similar workflows are available in abbreviated from the Workflows.  

```{r}
library(scRNAseq)
sce <- MacoskoRetinaData()

# Quality control
library(scater)
is.mito <- grepl("^MT-", rownames(sce))
qcstats <- perCellQCMetrics(sce, subsets = list(Mito = is.mito))
filtered <- quickPerCellQC(df = qcstats, percent_subsets = "subsets_Mito_percent")
sce <- sce[, !filtered$discard]

# Normalization  
sce <- logNormCounts(sce)

# feature selection  
library(scran)
dec <- modelGeneVar(sce)
hvg <- getTopHVGs(dec, prop = 0.1)

# dimensionality reduction
set.seed(1234)
sce <- runPCA(sce, ncomponents = 25, subset_row = hvg)
sce <- runUMAP(sce, dimred = "PCA", external_neighbors = TRUE)


# clustering
g <- buildSNNGraph(sce, use.dimred = "PCA")
colLabels(sce) <- factor(igraph::cluster_louvain(g)$membership)

# visualization
plotUMAP(sce, colour_by = "label")
```


# Chapter 6 Quality Control  
Low-quality libraries in scRNA-seq data can arise from a variety of sources such as cell damage during dissociation or failure in library preparation (e.g., inefficient reverse transcription or PCR amplification). **These usually manifest as “cells” with low total counts, few expressed genes and high mitochondrial or spike-in proportions**. These low-quality libraries are problematic as they can contribute to misleading results in downstream analyses:  

- They form their own distinct cluster(s), complicating interpretation of the results. This is most obviously driven by increased mitochondrial proportions or enrichment for nuclear RNAs after cell damage. In the worst case, low-quality libraries generated from different cell types can cluster together based on similarities in the damage-induced expression profiles, creating artificial intermediate states or trajectories between otherwise distinct subpopulations. Additionally, very small libraries can form their own clusters due to shifts in the mean upon transformation.  

- They distort the characterization of population heterogeneity during variance estimation or principal components analysis. The first few principal components will capture differences in quality rather than biology, reducing the effectiveness of dimensionality reduction. Similarly, genes with the largest variances will be driven by differences between low- and high-quality cells. The most obvious example involves low-quality libraries with very low counts where scaling normalization inflates the apparent variance of genes that happen to have a non-zero count in those libraries.  

- They contain genes that appear to be strongly “upregulated” due to aggressive scaling to normalize for small library sizes. This is most problematic for contaminating transcripts (e.g., from the ambient solution) that are present in all libraries at low but constant levels. Increased scaling in low-quality libraries transforms small counts for these transcripts in large normalized expression values, resulting in apparent upregulation compared to other cells. This can be misleading as the affected genes are often biologically sensible but are actually expressed in another subpopulation.  

To avoid - or at least mitigate - these problems, we need to remove these cells at the start of the analysis. This step is commonly referred to as quality control (QC) on the cells.  

scRNA-seq dataset from [PMID:29030468]
```{r}
library(scRNAseq)

sce.416b <- LunSpikeInData(which = "416b")

library(readr)
library(dplyr)
library(EnsDb.Mmusculus.v79)

x1 <- read_tsv("/home/yincy/git/Data/NCBI/E-MTAB-5522/counts_Calero_20160113.tsv")
x2 <- read_tsv("/home/yincy/git/Data/NCBI/E-MTAB-5522/counts_Calero_20160325.tsv")

counts <- left_join(x1, x2, by = c("GeneID" = "GeneID")) %>% 
    select(-contains("length")) %>% 
    filter(!grepl('^ERCC-|SIRV', GeneID)) %>% 
    tibble::column_to_rownames("GeneID") %>% 
    as.matrix()

length <- left_join(x1, x2, by = c("GeneID" = "GeneID")) %>% 
    select(GeneID, Length.x) %>% 
    filter(!grepl("^ERCC-|^SIRV", GeneID)) %>% 
    tibble::column_to_rownames("GeneID") %>% 
    magrittr::set_colnames("Length") %>% 
    as.data.frame()

length <- length[rownames(counts), , drop = F]
gs <- genes(EnsDb.Mmusculus.v79)
gs <- gs[match(rownames(counts), gs$gene_id) %>% na.omit() %>% as.integer(), ]

sample_info <- read_tsv("/home/yincy/git/Data/NCBI/E-MTAB-5522/E-MTAB-5522.sdrf.txt", 
                          col_names = T)
sample_info <- sample_info %>% 
    dplyr::rename('Source_Name' = "Source Name") %>% 
    dplyr::filter(grepl("^SLX-", Source_Name, ignore.case = F)) %>% 
    tibble::column_to_rownames('Source_Name')

sample_info <- sample_info[colnames(counts), ] %>% 
    tibble::rownames_to_column("Source_Name") %>% 
    dplyr::select(Source_Name, `Characteristics[cell type]`, `Characteristics[genotype]`,
           `Characteristics[phenotype]`, `Characteristics[strain]`, 
           `Material Type`, `Comment[spike sequence file]`, 
           `Comment[LIBRARY_SELECTION]`, `Assay Name`, 
           `Factor Value[spike-in addition]`)

alt_counts_ERCC <- left_join(x1, x2, by = c("GeneID" = "GeneID")) %>% 
    dplyr::select(-contains("length")) %>% 
    dplyr::filter(grepl('^ERCC-', GeneID)) %>% 
    tibble::column_to_rownames("GeneID") %>% 
    as.matrix()

alt_counts_SIRV <- left_join(x1, x2, by = c("GeneID" = "GeneID")) %>% 
    dplyr::select(-contains("length")) %>% 
    dplyr::filter(!grepl('^SIRV', GeneID)) %>% 
    tibble::column_to_rownames("GeneID") %>% 
    as.matrix()

alt_ERCC <- SummarizedExperiment(assays = list(ERCC = alt_counts_ERCC))
alt_SIRV <- SummarizedExperiment(assays = list(SIRV = alt_counts_SIRV))

sce.416b <- SingleCellExperiment(assays = list(counts = counts), 
                                 rowData = length, 
                                 colData = sample_info, 
                                 altExps = list(ERCC = alt_ERCC, SIRV = alt_SIRV))
```


## Choice of QC metrics  
We use several common QC metrics to identify low-quality cells based on their expression profiles. These metrics are described below in terms of reads for SMART-seq2 data, but the same definitions apply to UMI data generated by other technologies like MARS-seq and droplet-based protocols.  

- The library size is defined as the total sum of counts across all relevant features for each cell. Here, we will consider the relevant features to be the endogenous genes. Cells with small library sizes are of low quality as the RNA has been lost at some point during library preparation, either due to cell lysis or inefficient cDNA capture and amplification.  

- The number of expressed features in each cell is defined as the number of endogenous genes with non-zero counts for that cell. Any cell with very few expressed genes is likely to be of poor quality as the diverse transcript population has not been successfully captured.  

- The proportion of reads mapped to spike-in transcripts is calculated relative to the total count across all features (including spike-ins) for each cell. As the same amount of spike-in RNA should have been added to each cell, any enrichment in spike-in counts is symptomatic of loss of endogenous RNA. Thus, high proportions are indicative of poor-quality cells where endogenous RNA has been lost due to, e.g., partial cell lysis or RNA degradation during dissociation.  

- In the absence of spike-in transcripts, the proportion of reads mapped to genes in the mitochondrial genome can be used. High proportions are indicative of poor-quality cells (Islam et al. 2014; Ilicic et al. 2016), presumably because of loss of cytoplasmic RNA from perforated cells. The reasoning is that, in the presence of modest damage, the holes in the cell membrane permit efflux of individual transcript molecules but are too small to allow mitochondria to escape, leading to a relative enrichment of mitochondrial transcripts. For single-nuclei RNA-seq experiments, high proportions are also useful as they can mark cells where the cytoplasm has not been successfully stripped.  


For each cell, we calculate these QC metrics using the `perCellQCMetrics()` function from the scater package (McCarthy et al. 2017). The `sum` column contains the total count for each cell and the `detected` column contains the number of detected genes. The `subsets_Mito_percent` column contains the percentage of reads mapped to mitochondrial transcripts. (For demonstration purposes, we show two different approaches of determining the genomic location of each transcript.) Finally, the `altexps_ERCC_percent` column contains the percentage of reads mapped to ERCC transcripts.  

```{r}
location <- rowRanges(sce.416b)
is.mito <- any(seqnames(location)  == "MT")

chr.loc <- mapIds(EnsDb.Mmusculus.v79, 
                  keys = rownames(sce.416b), 
                  keytype = "GENEID", 
                  column = "SEQNAME")
is.mito.alt <- which(chr.loc == "MT")

library(scater)
df <- perCellQCMetrics(sce.416b, subsets = list(Mito = is.mito))
```












# Resources  
- http://bioconductor.org/books/release/OSCA/  



